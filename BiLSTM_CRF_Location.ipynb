{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "from copy import deepcopy\n",
    "from evaluating import Metrics\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(data_path,make_word2id =True):\n",
    "    word_lists = []\n",
    "    tag_lists = []\n",
    "    with open(data_path,'r',encoding='utf-8') as f:\n",
    "        word_list = []\n",
    "        tag_list = []\n",
    "        for line in f:\n",
    "            if line !='\\n':\n",
    "                line = line.strip('\\n').split()\n",
    "                if len(line) < 2:\n",
    "                    continue\n",
    "                word,tag = line[0],line[1]\n",
    "\n",
    "                word_list.append(word)\n",
    "                tag_list.append(tag)\n",
    "            else:\n",
    "                word_lists.append(word_list)\n",
    "                tag_lists.append(tag_list)\n",
    "                word_list = []\n",
    "                tag_list = []\n",
    "    def build_map(lists):\n",
    "        maps = {}\n",
    "        for sent in lists:\n",
    "            for word in sent:\n",
    "                if word not in maps:\n",
    "                    maps[word]=len(maps)\n",
    "        return maps\n",
    "\n",
    "    if make_word2id:\n",
    "        word2id = build_map(word_lists)\n",
    "        tag2id = build_map(tag_lists)\n",
    "        return word_lists,tag_lists,word2id,tag2id\n",
    "    else:\n",
    "        return word_lists,tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_maps(word2id, tag2id, for_crf=True):\n",
    "    word2id['<pad>'] = len(word2id)\n",
    "    tag2id['<pad>'] = len(tag2id)\n",
    "    # 如果是加了CRF的bilstm  那么还要加入<start> 和 <end>token\n",
    "    if for_crf:\n",
    "        word2id['<start>'] = len(word2id)\n",
    "        word2id['<end>'] = len(word2id)\n",
    "        tag2id['<start>'] = len(tag2id)\n",
    "        tag2id['<end>'] = len(tag2id)\n",
    "    return word2id, tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepocess_data_for_lstmcrf(word_lists, tag_lists, test=False):\n",
    "    assert len(word_lists) == len(tag_lists)\n",
    "    for i in range(len(word_lists)):\n",
    "        word_lists[i].append(\"<end>\")\n",
    "        if not test:  # 如果是测试数据，就不需要加end token了\n",
    "            tag_lists[i].append(\"<end>\")\n",
    "    return word_lists, tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM模型 工具函数\n",
    "def tensorized(batch,maps):\n",
    "    PAD = maps.get('<pad>')\n",
    "\n",
    "    max_len = len(batch[0])\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    batch_tensor = torch.ones(batch_size,max_len).long()*PAD\n",
    "    for i,sen in enumerate(batch):\n",
    "        for j,word in enumerate(sen):\n",
    "            batch_tensor[i][j] = maps.get(word)\n",
    "    #每个批次的长度\n",
    "    lengths = [len(sen) for sen in batch]\n",
    "\n",
    "    return batch_tensor,lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name):\n",
    "    \"\"\"用于保存模型\"\"\"\n",
    "    # with open(file_name, \"wb\") as f:\n",
    "    #     pickle.dump(model, f)\n",
    "    torch.save(model,file_name)\n",
    "def load_model(file_name):\n",
    "    \"\"\"用于加载模型\"\"\"\n",
    "    # with open(file_name, \"rb\") as f:\n",
    "        # model = pickle.load(f)\n",
    "    model = torch.load(file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexed(targets, tagset_size, start_id):\n",
    "    \"\"\"将targets中的数转化为在[T*T]大小序列中的索引,T是标注的种类\"\"\"\n",
    "    batch_size, max_len = targets.size()\n",
    "    for col in range(max_len-1, 0, -1):\n",
    "        targets[:, col] += (targets[:, col-1] * tagset_size)\n",
    "    targets[:, 0] += (start_id * tagset_size)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_lengths(word_lists,tag_lists):\n",
    "    pairs = list(zip(word_lists,tag_lists))\n",
    "    indice = sorted(range(len(pairs)),key = lambda k:len(pairs[k][0]),reverse = True)\n",
    "    pairs = [pairs[i] for i in indice]\n",
    "    word_lists,tag_lists = list(zip(*pairs))\n",
    "\n",
    "    return word_lists,tag_lists,indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_lstm_crf_loss(crf_scores, targets, tag2id):\n",
    "    \"\"\"计算双向LSTM-CRF模型的损失\n",
    "    该损失函数的计算可以参考:https://arxiv.org/pdf/1603.01360.pdf\n",
    "    \"\"\"\n",
    "    pad_id = tag2id.get('<pad>')\n",
    "    start_id = tag2id.get('<start>')\n",
    "    end_id = tag2id.get('<end>')\n",
    "\n",
    "    device = crf_scores.device\n",
    "\n",
    "    # targets:[B, L] crf_scores:[B, L, T, T]\n",
    "    batch_size, max_len = targets.size()\n",
    "    target_size = len(tag2id)\n",
    "\n",
    "    # mask = 1 - ((targets == pad_id) + (targets == end_id))  # [B, L]\n",
    "    mask = (targets != pad_id)\n",
    "    lengths = mask.sum(dim=1)\n",
    "    targets = indexed(targets, target_size, start_id)\n",
    "\n",
    "    # # 计算Golden scores方法１\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    targets = targets.masked_select(mask)  # [real_L]\n",
    "\n",
    "    flatten_scores = crf_scores.masked_select(\n",
    "        mask.view(batch_size, max_len, 1, 1).expand_as(crf_scores)\n",
    "    ).view(-1, target_size*target_size).contiguous()\n",
    "\n",
    "    golden_scores = flatten_scores.gather(\n",
    "        dim=1, index=targets.unsqueeze(1)).sum()\n",
    "\n",
    "\n",
    "    scores_upto_t = torch.zeros(batch_size, target_size).to(device)\n",
    "    for t in range(max_len):\n",
    "        # 当前时刻 有效的batch_size（因为有些序列比较短)\n",
    "        batch_size_t = (lengths > t).sum().item()\n",
    "        if t == 0:\n",
    "            scores_upto_t[:batch_size_t] = crf_scores[:batch_size_t,\n",
    "                                                      t, start_id, :]\n",
    "        else:\n",
    "            scores_upto_t[:batch_size_t] = torch.logsumexp(\n",
    "                crf_scores[:batch_size_t, t, :, :] +\n",
    "                scores_upto_t[:batch_size_t].unsqueeze(2),\n",
    "                dim=1\n",
    "            )\n",
    "    all_path_scores = scores_upto_t[:, end_id].sum()\n",
    "\n",
    "    # 训练大约两个epoch loss变成负数，从数学的角度上来说，loss = -logP\n",
    "    loss = (all_path_scores - golden_scores) / batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, out_size):\n",
    "        \"\"\"初始化参数：\n",
    "            vocab_size:字典的大小\n",
    "            emb_size:词向量的维数\n",
    "            hidden_size：隐向量的维数\n",
    "            out_size:标注的种类\n",
    "        \"\"\"\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.bilstm = nn.LSTM(emb_size, hidden_size,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=True)\n",
    "\n",
    "        self.lin = nn.Linear(2*hidden_size, out_size)\n",
    "\n",
    "    def forward(self, sents_tensor, lengths):\n",
    "        emb = self.embedding(sents_tensor)  # [B, L, emb_size]\n",
    "\n",
    "        packed = pack_padded_sequence(emb, lengths, batch_first=True)\n",
    "        rnn_out, _ = self.bilstm(packed)\n",
    "        # rnn_out:[B, L, hidden_size*2]\n",
    "        rnn_out, _ = pad_packed_sequence(rnn_out, batch_first=True)\n",
    "\n",
    "        scores = self.lin(rnn_out)  # [B, L, out_size]\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def test(self, sents_tensor, lengths, _):\n",
    "        \"\"\"第三个参数不会用到，加它是为了与BiLSTM_CRF保持同样的接口\"\"\"\n",
    "        logits = self.forward(sents_tensor, lengths)  # [B, L, out_size]\n",
    "        batch_max_value, batch_tagids = torch.max(logits, dim=2)\n",
    "\n",
    "        return batch_tagids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, out_size):\n",
    "        \"\"\"初始化参数：\n",
    "            vocab_size:字典的大小\n",
    "            emb_size:词向量的维数\n",
    "            hidden_size：隐向量的维数\n",
    "            out_size:标注的种类\n",
    "        \"\"\"\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        # self.bilstm = BiLSTM(vocab_size, emb_size, hidden_size, out_size)\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.bilstm = nn.LSTM(emb_size, hidden_size,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=True)\n",
    "\n",
    "        self.lin = nn.Linear(2*hidden_size, out_size)\n",
    "\n",
    "        # CRF实际上就是多学习一个转移矩阵 [out_size, out_size] 初始化为均匀分布\n",
    "        self.transition = nn.Parameter(\n",
    "            torch.ones(out_size, out_size) * 1/out_size)\n",
    "        # self.transition.data.zero_()\n",
    "\n",
    "    def forward(self, sents_tensor, lengths):\n",
    "        # [B, L, out_size]\n",
    "        emb = self.embedding(sents_tensor)  # [B, L, emb_size]\n",
    "\n",
    "        packed = pack_padded_sequence(emb, lengths, batch_first=True)\n",
    "        rnn_out, _ = self.bilstm(packed)\n",
    "        # rnn_out:[B, L, hidden_size*2]\n",
    "        rnn_out, _ = pad_packed_sequence(rnn_out, batch_first=True)\n",
    "\n",
    "        emission = self.lin(rnn_out)\n",
    "        # emission = self.bilstm(sents_tensor, lengths)\n",
    "\n",
    "        # 计算CRF scores, 这个scores大小为[B, L, out_size, out_size]\n",
    "        # 也就是每个字对应对应一个 [out_size, out_size]的矩阵\n",
    "        # 这个矩阵第i行第j列的元素的含义是：上一时刻tag为i，这一时刻tag为j的分数\n",
    "        batch_size, max_len, out_size = emission.size()\n",
    "        crf_scores = emission.unsqueeze(2).expand(-1, -1, out_size, -1) + self.transition.unsqueeze(0)\n",
    "\n",
    "        return crf_scores\n",
    "\n",
    "    def test(self, test_sents_tensor, lengths, tag2id):\n",
    "        \"\"\"使用维特比算法进行解码\"\"\"\n",
    "        start_id = tag2id['<start>']\n",
    "        end_id = tag2id['<end>']\n",
    "        pad = tag2id['<pad>']\n",
    "        tagset_size = len(tag2id)\n",
    "\n",
    "        crf_scores = self.forward(test_sents_tensor, lengths)\n",
    "        device = crf_scores.device\n",
    "        # B:batch_size, L:max_len, T:target set size\n",
    "        B, L, T, _ = crf_scores.size()\n",
    "        # viterbi[i, j, k]表示第i个句子，第j个字对应第k个标记的最大分数\n",
    "        viterbi = torch.zeros(B, L, T).to(device)\n",
    "        # backpointer[i, j, k]表示第i个句子，第j个字对应第k个标记时前一个标记的id，用于回溯\n",
    "        backpointer = (torch.zeros(B, L, T).long() * end_id).to(device)\n",
    "        lengths = torch.LongTensor(lengths).to(device)\n",
    "        # 向前递推\n",
    "        for step in range(L):\n",
    "            batch_size_t = (lengths > step).sum().item()\n",
    "            if step == 0:\n",
    "                # 第一个字它的前一个标记只能是start_id\n",
    "                viterbi[:batch_size_t, step,\n",
    "                        :] = crf_scores[: batch_size_t, step, start_id, :]\n",
    "                backpointer[: batch_size_t, step, :] = start_id\n",
    "            else:\n",
    "                max_scores, prev_tags = torch.max(\n",
    "                    viterbi[:batch_size_t, step-1, :].unsqueeze(2) +\n",
    "                    crf_scores[:batch_size_t, step, :, :],     # [B, T, T]\n",
    "                    dim=1\n",
    "                )\n",
    "                viterbi[:batch_size_t, step, :] = max_scores\n",
    "                backpointer[:batch_size_t, step, :] = prev_tags\n",
    "\n",
    "        # 在回溯的时候我们只需要用到backpointer矩阵\n",
    "        backpointer = backpointer.view(B, -1)  # [B, L * T]\n",
    "        tagids = []  # 存放结果\n",
    "        tags_t = None\n",
    "        for step in range(L-1, 0, -1):\n",
    "            batch_size_t = (lengths > step).sum().item()\n",
    "            if step == L-1:\n",
    "                index = torch.ones(batch_size_t).long() * (step * tagset_size)\n",
    "                index = index.to(device)\n",
    "                index += end_id\n",
    "            else:\n",
    "                prev_batch_size_t = len(tags_t)\n",
    "\n",
    "                new_in_batch = torch.LongTensor(\n",
    "                    [end_id] * (batch_size_t - prev_batch_size_t)).to(device)\n",
    "                offset = torch.cat(\n",
    "                    [tags_t, new_in_batch],\n",
    "                    dim=0\n",
    "                )  # 这个offset实际上就是前一时刻的\n",
    "                index = torch.ones(batch_size_t).long() * (step * tagset_size)\n",
    "                index = index.to(device)\n",
    "                index += offset.long()\n",
    "\n",
    "            try:\n",
    "                tags_t = backpointer[:batch_size_t].gather(\n",
    "                    dim=1, index=index.unsqueeze(1).long())\n",
    "            except RuntimeError:\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            tags_t = tags_t.squeeze(1)\n",
    "            tagids.append(tags_t.tolist())\n",
    "\n",
    "        # tagids:[L-1]（L-1是因为扣去了end_token),大小的liebiao\n",
    "        # 其中列表内的元素是该batch在该时刻的标记\n",
    "        # 下面修正其顺序，并将维度转换为 [B, L]\n",
    "        tagids = list(zip_longest(*reversed(tagids), fillvalue=pad))\n",
    "        tagids = torch.Tensor(tagids).long()\n",
    "\n",
    "        # 返回解码的结果\n",
    "        return tagids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置lstm训练参数\n",
    "class TrainingConfig(object):\n",
    "    batch_size = 32\n",
    "    # 学习速率\n",
    "    lr = 0.0001\n",
    "    epoches = 2\n",
    "    print_step = 5\n",
    "\n",
    "\n",
    "class LSTMConfig(object):\n",
    "    emb_size = 128  # 词向量的维数\n",
    "    hidden_size = 128  # lstm隐向量的维数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BILSTM_Model(object):\n",
    "    def __init__(self, vocab_size, out_size, crf=True):\n",
    "        \"\"\"功能：对LSTM的模型进行训练与测试\n",
    "           参数:\n",
    "            vocab_size:词典大小\n",
    "            out_size:标注种类\n",
    "            crf选择是否添加CRF层\"\"\"\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # 加载模型参数\n",
    "        self.emb_size = LSTMConfig.emb_size\n",
    "        self.hidden_size = LSTMConfig.hidden_size\n",
    "\n",
    "        self.crf = crf\n",
    "        # 根据是否添加crf初始化不同的模型 选择不一样的损失计算函数\n",
    "        if not crf:\n",
    "            self.model = BiLSTM(vocab_size, self.emb_size,\n",
    "                                self.hidden_size, out_size).to(self.device)\n",
    "            self.cal_loss_func = cal_loss\n",
    "        else:\n",
    "            self.model = BiLSTM_CRF(vocab_size, self.emb_size,\n",
    "                                    self.hidden_size, out_size).to(self.device)\n",
    "            self.cal_loss_func = cal_lstm_crf_loss\n",
    "\n",
    "        # 加载训练参数：\n",
    "        self.epoches = TrainingConfig.epoches\n",
    "        self.print_step = TrainingConfig.print_step\n",
    "        self.lr = TrainingConfig.lr\n",
    "        self.batch_size = TrainingConfig.batch_size\n",
    "\n",
    "        # 初始化优化器\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        # 初始化其他指标\n",
    "        self.step = 0\n",
    "        self._best_val_loss = 1e18\n",
    "        self.best_model = None\n",
    "\n",
    "    def train(self, word_lists, tag_lists,\n",
    "              dev_word_lists, dev_tag_lists,\n",
    "              word2id, tag2id):\n",
    "        # 对数据集按照长度进行排序\n",
    "        word_lists, tag_lists, _ = sort_by_lengths(word_lists, tag_lists)\n",
    "        dev_word_lists, dev_tag_lists, _ = sort_by_lengths(dev_word_lists, dev_tag_lists)\n",
    "\n",
    "        B = self.batch_size\n",
    "        for e in range(1, self.epoches+1):\n",
    "            self.step = 0\n",
    "            losses = 0.\n",
    "            for ind in range(0, len(word_lists), B):\n",
    "                batch_sents = word_lists[ind:ind+B]\n",
    "                batch_tags = tag_lists[ind:ind+B]\n",
    "\n",
    "                losses += self.train_step(batch_sents,\n",
    "                                          batch_tags, word2id, tag2id)\n",
    "\n",
    "                if self.step % TrainingConfig.print_step == 0:\n",
    "                    total_step = (len(word_lists) // B + 1)\n",
    "                    print(\"Epoch {}, step/total_step: {}/{} {:.2f}% Loss:{:.4f}\".format(\n",
    "                        e, self.step, total_step,\n",
    "                        100. * self.step / total_step,\n",
    "                        losses / self.print_step\n",
    "                    ))\n",
    "                    losses = 0.\n",
    "\n",
    "            # 每轮结束测试在验证集上的性能，保存最好的一个\n",
    "            val_loss = self.validate(dev_word_lists, dev_tag_lists, word2id, tag2id)\n",
    "            print(\"Epoch {}, Val Loss:{:.4f}\".format(e, val_loss))\n",
    "\n",
    "    def train_step(self, batch_sents, batch_tags, word2id, tag2id):\n",
    "        self.model.train()\n",
    "        self.step += 1\n",
    "        # 准备数据\n",
    "        tensorized_sents, lengths = tensorized(batch_sents, word2id)\n",
    "        tensorized_sents = tensorized_sents.to(self.device)\n",
    "        targets, lengths = tensorized(batch_tags, tag2id)\n",
    "        targets = targets.to(self.device)\n",
    "\n",
    "        # forward\n",
    "        scores = self.model(tensorized_sents, lengths)\n",
    "\n",
    "        # 计算损失 更新参数\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.cal_loss_func(scores, targets, tag2id).to(self.device)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def validate(self, dev_word_lists, dev_tag_lists, word2id, tag2id):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = 0.\n",
    "            val_step = 0\n",
    "            for ind in range(0, len(dev_word_lists), self.batch_size):\n",
    "                val_step += 1\n",
    "                # 准备batch数据\n",
    "                batch_sents = dev_word_lists[ind:ind+self.batch_size]\n",
    "                batch_tags = dev_tag_lists[ind:ind+self.batch_size]\n",
    "                tensorized_sents, lengths = tensorized(\n",
    "                    batch_sents, word2id)\n",
    "                tensorized_sents = tensorized_sents.to(self.device)\n",
    "                targets, lengths = tensorized(batch_tags, tag2id)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                # forward\n",
    "                scores = self.model(tensorized_sents, lengths)\n",
    "\n",
    "                # 计算损失\n",
    "                loss = self.cal_loss_func(\n",
    "                    scores, targets, tag2id).to(self.device)\n",
    "                val_losses += loss.item()\n",
    "            val_loss = val_losses / val_step\n",
    "\n",
    "            if val_loss < self._best_val_loss:\n",
    "                print(\"保存模型...\")\n",
    "                self.best_model = deepcopy(self.model)\n",
    "                self._best_val_loss = val_loss\n",
    "\n",
    "            return val_loss\n",
    "\n",
    "    def test(self, word_lists, tag_lists, word2id, tag2id):\n",
    "        \"\"\"返回最佳模型在测试集上的预测结果\"\"\"\n",
    "        # 准备数据\n",
    "        word_lists, tag_lists, indices = sort_by_lengths(word_lists, tag_lists)\n",
    "        # tensorized_sents, lengths = tensorized(word_lists, word2id)\n",
    "        # tensorized_sents = tensorized_sents.to(self.device)\n",
    "\n",
    "        self.best_model.eval()\n",
    "        # 将id转化为标注\n",
    "        pred_tag_lists = []\n",
    "        with torch.no_grad():\n",
    "            for ind in range(0, len(word_lists), self.batch_size):\n",
    "                batch_sents = word_lists[ind:ind+self.batch_size]\n",
    "                tensorized_sents, lengths = tensorized(batch_sents, word2id)\n",
    "                tensorized_sents = tensorized_sents.to(self.device)\n",
    "            \n",
    "                batch_tagids = self.best_model.test(\n",
    "                    tensorized_sents, lengths, tag2id)\n",
    "\n",
    "                id2tag = dict((id_, tag) for tag, id_ in tag2id.items())\n",
    "                for i, ids in enumerate(batch_tagids):\n",
    "                    tag_list = []\n",
    "                    if self.crf:\n",
    "                        for j in range(lengths[i] - 1):  # crf解码过程中，end被舍弃\n",
    "                            tag_list.append(id2tag[ids[j].item()])\n",
    "                    else:\n",
    "                        for j in range(lengths[i]):\n",
    "                            tag_list.append(id2tag[ids[j].item()])\n",
    "                    pred_tag_lists.append(tag_list)\n",
    "\n",
    "        # indices存有根据长度排序后的索引映射的信息\n",
    "        # 比如若indices = [1, 2, 0] 则说明原先索引为1的元素映射到的新的索引是0，\n",
    "        # 索引为2的元素映射到新的索引是1...\n",
    "        # 下面根据indices将pred_tag_lists和tag_lists转化为原来的顺序\n",
    "        ind_maps = sorted(list(enumerate(indices)), key=lambda e: e[1])\n",
    "        indices, _ = list(zip(*ind_maps))\n",
    "        pred_tag_lists = [pred_tag_lists[i] for i in indices]\n",
    "        tag_lists = [tag_lists[i] for i in indices]\n",
    "\n",
    "        return pred_tag_lists, tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_train_and_eval(train_data, dev_data, test_data,\n",
    "                          word2id, tag2id, crf=True, remove_O=False):\n",
    "    train_word_lists, train_tag_lists = train_data\n",
    "    dev_word_lists, dev_tag_lists = dev_data\n",
    "    test_word_lists, test_tag_lists = test_data\n",
    "\n",
    "    start = time.time()\n",
    "    vocab_size = len(word2id)\n",
    "    out_size = len(tag2id)\n",
    "    bilstm_model = BILSTM_Model(vocab_size, out_size, crf=crf)\n",
    "    bilstm_model.train(train_word_lists, train_tag_lists,\n",
    "                       dev_word_lists, dev_tag_lists, word2id, tag2id)\n",
    "\n",
    "    model_name = \"bilstm_crf\" if crf else \"bilstm\"\n",
    "    save_model(bilstm_model, \"./models/\"+ \"new\" +model_name+\".pkl\")\n",
    "\n",
    "    print(\"训练完毕,共用时{}秒.\".format(int(time.time()-start)))\n",
    "    pred_tag_lists, test_tag_lists = bilstm_model.test(\n",
    "        test_word_lists, test_tag_lists, word2id, tag2id)\n",
    "\n",
    "    return pred_tag_lists,test_tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据\n",
    "data_path = 'data/all_data.txt'\n",
    "word_lists,tag_lists,word2id,tag2id = build_corpus(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据处理\n",
    "crf_word2id, crf_tag2id = extend_maps(word2id, tag2id, for_crf=True)\n",
    "word_lists, tag_lists = prepocess_data_for_lstmcrf(word_lists, tag_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(944823, 944823)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "len(word_lists),len(tag_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_lists,dev_word_lists,test_word_lists = word_lists[:800000],word_lists[800000:900000],word_lists[900000:]\n",
    "train_tag_lists,dev_tag_lists,test_tag_lists = tag_lists[:800000],tag_lists[800000:900000],tag_lists[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44823"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "len(test_tag_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch 2, step/total_step: 23255/25001 93.02% Loss:0.2653\n",
      "Epoch 2, step/total_step: 23260/25001 93.04% Loss:0.2574\n",
      "Epoch 2, step/total_step: 23265/25001 93.06% Loss:0.2393\n",
      "Epoch 2, step/total_step: 23270/25001 93.08% Loss:0.3358\n",
      "Epoch 2, step/total_step: 23275/25001 93.10% Loss:0.2706\n",
      "Epoch 2, step/total_step: 23280/25001 93.12% Loss:0.2356\n",
      "Epoch 2, step/total_step: 23285/25001 93.14% Loss:0.2687\n",
      "Epoch 2, step/total_step: 23290/25001 93.16% Loss:0.2401\n",
      "Epoch 2, step/total_step: 23295/25001 93.18% Loss:0.2604\n",
      "Epoch 2, step/total_step: 23300/25001 93.20% Loss:0.2813\n",
      "Epoch 2, step/total_step: 23305/25001 93.22% Loss:0.2158\n",
      "Epoch 2, step/total_step: 23310/25001 93.24% Loss:0.3183\n",
      "Epoch 2, step/total_step: 23315/25001 93.26% Loss:0.2260\n",
      "Epoch 2, step/total_step: 23320/25001 93.28% Loss:0.2508\n",
      "Epoch 2, step/total_step: 23325/25001 93.30% Loss:0.3585\n",
      "Epoch 2, step/total_step: 23330/25001 93.32% Loss:0.2698\n",
      "Epoch 2, step/total_step: 23335/25001 93.34% Loss:0.3328\n",
      "Epoch 2, step/total_step: 23340/25001 93.36% Loss:0.2498\n",
      "Epoch 2, step/total_step: 23345/25001 93.38% Loss:0.2514\n",
      "Epoch 2, step/total_step: 23350/25001 93.40% Loss:0.1699\n",
      "Epoch 2, step/total_step: 23355/25001 93.42% Loss:0.2559\n",
      "Epoch 2, step/total_step: 23360/25001 93.44% Loss:0.2441\n",
      "Epoch 2, step/total_step: 23365/25001 93.46% Loss:0.2284\n",
      "Epoch 2, step/total_step: 23370/25001 93.48% Loss:0.1906\n",
      "Epoch 2, step/total_step: 23375/25001 93.50% Loss:0.2708\n",
      "Epoch 2, step/total_step: 23380/25001 93.52% Loss:0.1711\n",
      "Epoch 2, step/total_step: 23385/25001 93.54% Loss:0.3811\n",
      "Epoch 2, step/total_step: 23390/25001 93.56% Loss:0.2037\n",
      "Epoch 2, step/total_step: 23395/25001 93.58% Loss:0.2570\n",
      "Epoch 2, step/total_step: 23400/25001 93.60% Loss:0.2622\n",
      "Epoch 2, step/total_step: 23405/25001 93.62% Loss:0.2646\n",
      "Epoch 2, step/total_step: 23410/25001 93.64% Loss:0.2699\n",
      "Epoch 2, step/total_step: 23415/25001 93.66% Loss:0.2492\n",
      "Epoch 2, step/total_step: 23420/25001 93.68% Loss:0.3331\n",
      "Epoch 2, step/total_step: 23425/25001 93.70% Loss:0.1933\n",
      "Epoch 2, step/total_step: 23430/25001 93.72% Loss:0.3636\n",
      "Epoch 2, step/total_step: 23435/25001 93.74% Loss:0.4564\n",
      "Epoch 2, step/total_step: 23440/25001 93.76% Loss:0.1935\n",
      "Epoch 2, step/total_step: 23445/25001 93.78% Loss:0.4411\n",
      "Epoch 2, step/total_step: 23450/25001 93.80% Loss:0.3560\n",
      "Epoch 2, step/total_step: 23455/25001 93.82% Loss:0.2479\n",
      "Epoch 2, step/total_step: 23460/25001 93.84% Loss:0.2217\n",
      "Epoch 2, step/total_step: 23465/25001 93.86% Loss:0.2706\n",
      "Epoch 2, step/total_step: 23470/25001 93.88% Loss:0.3560\n",
      "Epoch 2, step/total_step: 23475/25001 93.90% Loss:0.2607\n",
      "Epoch 2, step/total_step: 23480/25001 93.92% Loss:0.2677\n",
      "Epoch 2, step/total_step: 23485/25001 93.94% Loss:0.2260\n",
      "Epoch 2, step/total_step: 23490/25001 93.96% Loss:0.2345\n",
      "Epoch 2, step/total_step: 23495/25001 93.98% Loss:0.2792\n",
      "Epoch 2, step/total_step: 23500/25001 94.00% Loss:0.1890\n",
      "Epoch 2, step/total_step: 23505/25001 94.02% Loss:0.3370\n",
      "Epoch 2, step/total_step: 23510/25001 94.04% Loss:0.2090\n",
      "Epoch 2, step/total_step: 23515/25001 94.06% Loss:0.2901\n",
      "Epoch 2, step/total_step: 23520/25001 94.08% Loss:0.2405\n",
      "Epoch 2, step/total_step: 23525/25001 94.10% Loss:0.3152\n",
      "Epoch 2, step/total_step: 23530/25001 94.12% Loss:0.2244\n",
      "Epoch 2, step/total_step: 23535/25001 94.14% Loss:0.1396\n",
      "Epoch 2, step/total_step: 23540/25001 94.16% Loss:0.3924\n",
      "Epoch 2, step/total_step: 23545/25001 94.18% Loss:0.2867\n",
      "Epoch 2, step/total_step: 23550/25001 94.20% Loss:0.3446\n",
      "Epoch 2, step/total_step: 23555/25001 94.22% Loss:0.2206\n",
      "Epoch 2, step/total_step: 23560/25001 94.24% Loss:0.3784\n",
      "Epoch 2, step/total_step: 23565/25001 94.26% Loss:0.2360\n",
      "Epoch 2, step/total_step: 23570/25001 94.28% Loss:0.3191\n",
      "Epoch 2, step/total_step: 23575/25001 94.30% Loss:0.2414\n",
      "Epoch 2, step/total_step: 23580/25001 94.32% Loss:0.1452\n",
      "Epoch 2, step/total_step: 23585/25001 94.34% Loss:0.2432\n",
      "Epoch 2, step/total_step: 23590/25001 94.36% Loss:0.3406\n",
      "Epoch 2, step/total_step: 23595/25001 94.38% Loss:0.2489\n",
      "Epoch 2, step/total_step: 23600/25001 94.40% Loss:0.2734\n",
      "Epoch 2, step/total_step: 23605/25001 94.42% Loss:0.3455\n",
      "Epoch 2, step/total_step: 23610/25001 94.44% Loss:0.2175\n",
      "Epoch 2, step/total_step: 23615/25001 94.46% Loss:0.2545\n",
      "Epoch 2, step/total_step: 23620/25001 94.48% Loss:0.2897\n",
      "Epoch 2, step/total_step: 23625/25001 94.50% Loss:0.2545\n",
      "Epoch 2, step/total_step: 23630/25001 94.52% Loss:0.3327\n",
      "Epoch 2, step/total_step: 23635/25001 94.54% Loss:0.2905\n",
      "Epoch 2, step/total_step: 23640/25001 94.56% Loss:0.2028\n",
      "Epoch 2, step/total_step: 23645/25001 94.58% Loss:0.3329\n",
      "Epoch 2, step/total_step: 23650/25001 94.60% Loss:0.2735\n",
      "Epoch 2, step/total_step: 23655/25001 94.62% Loss:0.2422\n",
      "Epoch 2, step/total_step: 23660/25001 94.64% Loss:0.2404\n",
      "Epoch 2, step/total_step: 23665/25001 94.66% Loss:0.2323\n",
      "Epoch 2, step/total_step: 23670/25001 94.68% Loss:0.1589\n",
      "Epoch 2, step/total_step: 23675/25001 94.70% Loss:0.1730\n",
      "Epoch 2, step/total_step: 23680/25001 94.72% Loss:0.2088\n",
      "Epoch 2, step/total_step: 23685/25001 94.74% Loss:0.2306\n",
      "Epoch 2, step/total_step: 23690/25001 94.76% Loss:0.2422\n",
      "Epoch 2, step/total_step: 23695/25001 94.78% Loss:0.1910\n",
      "Epoch 2, step/total_step: 23700/25001 94.80% Loss:0.2565\n",
      "Epoch 2, step/total_step: 23705/25001 94.82% Loss:0.2021\n",
      "Epoch 2, step/total_step: 23710/25001 94.84% Loss:0.2424\n",
      "Epoch 2, step/total_step: 23715/25001 94.86% Loss:0.2152\n",
      "Epoch 2, step/total_step: 23720/25001 94.88% Loss:0.1326\n",
      "Epoch 2, step/total_step: 23725/25001 94.90% Loss:0.1848\n",
      "Epoch 2, step/total_step: 23730/25001 94.92% Loss:0.3163\n",
      "Epoch 2, step/total_step: 23735/25001 94.94% Loss:0.2629\n",
      "Epoch 2, step/total_step: 23740/25001 94.96% Loss:0.3233\n",
      "Epoch 2, step/total_step: 23745/25001 94.98% Loss:0.3533\n",
      "Epoch 2, step/total_step: 23750/25001 95.00% Loss:0.3614\n",
      "Epoch 2, step/total_step: 23755/25001 95.02% Loss:0.3521\n",
      "Epoch 2, step/total_step: 23760/25001 95.04% Loss:0.2148\n",
      "Epoch 2, step/total_step: 23765/25001 95.06% Loss:0.3238\n",
      "Epoch 2, step/total_step: 23770/25001 95.08% Loss:0.2418\n",
      "Epoch 2, step/total_step: 23775/25001 95.10% Loss:0.2262\n",
      "Epoch 2, step/total_step: 23780/25001 95.12% Loss:0.3413\n",
      "Epoch 2, step/total_step: 23785/25001 95.14% Loss:0.2216\n",
      "Epoch 2, step/total_step: 23790/25001 95.16% Loss:0.3097\n",
      "Epoch 2, step/total_step: 23795/25001 95.18% Loss:0.3411\n",
      "Epoch 2, step/total_step: 23800/25001 95.20% Loss:0.3235\n",
      "Epoch 2, step/total_step: 23805/25001 95.22% Loss:0.2541\n",
      "Epoch 2, step/total_step: 23810/25001 95.24% Loss:0.2849\n",
      "Epoch 2, step/total_step: 23815/25001 95.26% Loss:0.2946\n",
      "Epoch 2, step/total_step: 23820/25001 95.28% Loss:0.3275\n",
      "Epoch 2, step/total_step: 23825/25001 95.30% Loss:0.2942\n",
      "Epoch 2, step/total_step: 23830/25001 95.32% Loss:0.2289\n",
      "Epoch 2, step/total_step: 23835/25001 95.34% Loss:0.2224\n",
      "Epoch 2, step/total_step: 23840/25001 95.36% Loss:0.2131\n",
      "Epoch 2, step/total_step: 23845/25001 95.38% Loss:0.2100\n",
      "Epoch 2, step/total_step: 23850/25001 95.40% Loss:0.2532\n",
      "Epoch 2, step/total_step: 23855/25001 95.42% Loss:0.2782\n",
      "Epoch 2, step/total_step: 23860/25001 95.44% Loss:0.2161\n",
      "Epoch 2, step/total_step: 23865/25001 95.46% Loss:0.2792\n",
      "Epoch 2, step/total_step: 23870/25001 95.48% Loss:0.2154\n",
      "Epoch 2, step/total_step: 23875/25001 95.50% Loss:0.2538\n",
      "Epoch 2, step/total_step: 23880/25001 95.52% Loss:0.1937\n",
      "Epoch 2, step/total_step: 23885/25001 95.54% Loss:0.2639\n",
      "Epoch 2, step/total_step: 23890/25001 95.56% Loss:0.2701\n",
      "Epoch 2, step/total_step: 23895/25001 95.58% Loss:0.1585\n",
      "Epoch 2, step/total_step: 23900/25001 95.60% Loss:0.2499\n",
      "Epoch 2, step/total_step: 23905/25001 95.62% Loss:0.2372\n",
      "Epoch 2, step/total_step: 23910/25001 95.64% Loss:0.2181\n",
      "Epoch 2, step/total_step: 23915/25001 95.66% Loss:0.1674\n",
      "Epoch 2, step/total_step: 23920/25001 95.68% Loss:0.2344\n",
      "Epoch 2, step/total_step: 23925/25001 95.70% Loss:0.2170\n",
      "Epoch 2, step/total_step: 23930/25001 95.72% Loss:0.2066\n",
      "Epoch 2, step/total_step: 23935/25001 95.74% Loss:0.2855\n",
      "Epoch 2, step/total_step: 23940/25001 95.76% Loss:0.3825\n",
      "Epoch 2, step/total_step: 23945/25001 95.78% Loss:0.2351\n",
      "Epoch 2, step/total_step: 23950/25001 95.80% Loss:0.2707\n",
      "Epoch 2, step/total_step: 23955/25001 95.82% Loss:0.2237\n",
      "Epoch 2, step/total_step: 23960/25001 95.84% Loss:0.4857\n",
      "Epoch 2, step/total_step: 23965/25001 95.86% Loss:0.2133\n",
      "Epoch 2, step/total_step: 23970/25001 95.88% Loss:0.2130\n",
      "Epoch 2, step/total_step: 23975/25001 95.90% Loss:0.2113\n",
      "Epoch 2, step/total_step: 23980/25001 95.92% Loss:0.2777\n",
      "Epoch 2, step/total_step: 23985/25001 95.94% Loss:0.2215\n",
      "Epoch 2, step/total_step: 23990/25001 95.96% Loss:0.1961\n",
      "Epoch 2, step/total_step: 23995/25001 95.98% Loss:0.3008\n",
      "Epoch 2, step/total_step: 24000/25001 96.00% Loss:0.1955\n",
      "Epoch 2, step/total_step: 24005/25001 96.02% Loss:0.3301\n",
      "Epoch 2, step/total_step: 24010/25001 96.04% Loss:0.2433\n",
      "Epoch 2, step/total_step: 24015/25001 96.06% Loss:0.1934\n",
      "Epoch 2, step/total_step: 24020/25001 96.08% Loss:0.2145\n",
      "Epoch 2, step/total_step: 24025/25001 96.10% Loss:0.2276\n",
      "Epoch 2, step/total_step: 24030/25001 96.12% Loss:0.1801\n",
      "Epoch 2, step/total_step: 24035/25001 96.14% Loss:0.1827\n",
      "Epoch 2, step/total_step: 24040/25001 96.16% Loss:0.1983\n",
      "Epoch 2, step/total_step: 24045/25001 96.18% Loss:0.2683\n",
      "Epoch 2, step/total_step: 24050/25001 96.20% Loss:0.1911\n",
      "Epoch 2, step/total_step: 24055/25001 96.22% Loss:0.2056\n",
      "Epoch 2, step/total_step: 24060/25001 96.24% Loss:0.2026\n",
      "Epoch 2, step/total_step: 24065/25001 96.26% Loss:0.2900\n",
      "Epoch 2, step/total_step: 24070/25001 96.28% Loss:0.2467\n",
      "Epoch 2, step/total_step: 24075/25001 96.30% Loss:0.3331\n",
      "Epoch 2, step/total_step: 24080/25001 96.32% Loss:0.1171\n",
      "Epoch 2, step/total_step: 24085/25001 96.34% Loss:0.2679\n",
      "Epoch 2, step/total_step: 24090/25001 96.36% Loss:0.3381\n",
      "Epoch 2, step/total_step: 24095/25001 96.38% Loss:0.2754\n",
      "Epoch 2, step/total_step: 24100/25001 96.40% Loss:0.2480\n",
      "Epoch 2, step/total_step: 24105/25001 96.42% Loss:0.1548\n",
      "Epoch 2, step/total_step: 24110/25001 96.44% Loss:0.1736\n",
      "Epoch 2, step/total_step: 24115/25001 96.46% Loss:0.1583\n",
      "Epoch 2, step/total_step: 24120/25001 96.48% Loss:0.2477\n",
      "Epoch 2, step/total_step: 24125/25001 96.50% Loss:0.2065\n",
      "Epoch 2, step/total_step: 24130/25001 96.52% Loss:0.1972\n",
      "Epoch 2, step/total_step: 24135/25001 96.54% Loss:0.1949\n",
      "Epoch 2, step/total_step: 24140/25001 96.56% Loss:0.2195\n",
      "Epoch 2, step/total_step: 24145/25001 96.58% Loss:0.2476\n",
      "Epoch 2, step/total_step: 24150/25001 96.60% Loss:0.2402\n",
      "Epoch 2, step/total_step: 24155/25001 96.62% Loss:0.1926\n",
      "Epoch 2, step/total_step: 24160/25001 96.64% Loss:0.2400\n",
      "Epoch 2, step/total_step: 24165/25001 96.66% Loss:0.2414\n",
      "Epoch 2, step/total_step: 24170/25001 96.68% Loss:0.2300\n",
      "Epoch 2, step/total_step: 24175/25001 96.70% Loss:0.1845\n",
      "Epoch 2, step/total_step: 24180/25001 96.72% Loss:0.1734\n",
      "Epoch 2, step/total_step: 24185/25001 96.74% Loss:0.2578\n",
      "Epoch 2, step/total_step: 24190/25001 96.76% Loss:0.2134\n",
      "Epoch 2, step/total_step: 24195/25001 96.78% Loss:0.1913\n",
      "Epoch 2, step/total_step: 24200/25001 96.80% Loss:0.3802\n",
      "Epoch 2, step/total_step: 24205/25001 96.82% Loss:0.2641\n",
      "Epoch 2, step/total_step: 24210/25001 96.84% Loss:0.2640\n",
      "Epoch 2, step/total_step: 24215/25001 96.86% Loss:0.3400\n",
      "Epoch 2, step/total_step: 24220/25001 96.88% Loss:0.2012\n",
      "Epoch 2, step/total_step: 24225/25001 96.90% Loss:0.2144\n",
      "Epoch 2, step/total_step: 24230/25001 96.92% Loss:0.2113\n",
      "Epoch 2, step/total_step: 24235/25001 96.94% Loss:0.1657\n",
      "Epoch 2, step/total_step: 24240/25001 96.96% Loss:0.0994\n",
      "Epoch 2, step/total_step: 24245/25001 96.98% Loss:0.2552\n",
      "Epoch 2, step/total_step: 24250/25001 97.00% Loss:0.2257\n",
      "Epoch 2, step/total_step: 24255/25001 97.02% Loss:0.1944\n",
      "Epoch 2, step/total_step: 24260/25001 97.04% Loss:0.2320\n",
      "Epoch 2, step/total_step: 24265/25001 97.06% Loss:0.2715\n",
      "Epoch 2, step/total_step: 24270/25001 97.08% Loss:0.3009\n",
      "Epoch 2, step/total_step: 24275/25001 97.10% Loss:0.1660\n",
      "Epoch 2, step/total_step: 24280/25001 97.12% Loss:0.2145\n",
      "Epoch 2, step/total_step: 24285/25001 97.14% Loss:0.1870\n",
      "Epoch 2, step/total_step: 24290/25001 97.16% Loss:0.1811\n",
      "Epoch 2, step/total_step: 24295/25001 97.18% Loss:0.2373\n",
      "Epoch 2, step/total_step: 24300/25001 97.20% Loss:0.2213\n",
      "Epoch 2, step/total_step: 24305/25001 97.22% Loss:0.1805\n",
      "Epoch 2, step/total_step: 24310/25001 97.24% Loss:0.2385\n",
      "Epoch 2, step/total_step: 24315/25001 97.26% Loss:0.2280\n",
      "Epoch 2, step/total_step: 24320/25001 97.28% Loss:0.1523\n",
      "Epoch 2, step/total_step: 24325/25001 97.30% Loss:0.2162\n",
      "Epoch 2, step/total_step: 24330/25001 97.32% Loss:0.2589\n",
      "Epoch 2, step/total_step: 24335/25001 97.34% Loss:0.2676\n",
      "Epoch 2, step/total_step: 24340/25001 97.36% Loss:0.2367\n",
      "Epoch 2, step/total_step: 24345/25001 97.38% Loss:0.2265\n",
      "Epoch 2, step/total_step: 24350/25001 97.40% Loss:0.2224\n",
      "Epoch 2, step/total_step: 24355/25001 97.42% Loss:0.2180\n",
      "Epoch 2, step/total_step: 24360/25001 97.44% Loss:0.1996\n",
      "Epoch 2, step/total_step: 24365/25001 97.46% Loss:0.3064\n",
      "Epoch 2, step/total_step: 24370/25001 97.48% Loss:0.2085\n",
      "Epoch 2, step/total_step: 24375/25001 97.50% Loss:0.2220\n",
      "Epoch 2, step/total_step: 24380/25001 97.52% Loss:0.2704\n",
      "Epoch 2, step/total_step: 24385/25001 97.54% Loss:0.1444\n",
      "Epoch 2, step/total_step: 24390/25001 97.56% Loss:0.1917\n",
      "Epoch 2, step/total_step: 24395/25001 97.58% Loss:0.1086\n",
      "Epoch 2, step/total_step: 24400/25001 97.60% Loss:0.1554\n",
      "Epoch 2, step/total_step: 24405/25001 97.62% Loss:0.1785\n",
      "Epoch 2, step/total_step: 24410/25001 97.64% Loss:0.2101\n",
      "Epoch 2, step/total_step: 24415/25001 97.66% Loss:0.1581\n",
      "Epoch 2, step/total_step: 24420/25001 97.68% Loss:0.2949\n",
      "Epoch 2, step/total_step: 24425/25001 97.70% Loss:0.2275\n",
      "Epoch 2, step/total_step: 24430/25001 97.72% Loss:0.2603\n",
      "Epoch 2, step/total_step: 24435/25001 97.74% Loss:0.2641\n",
      "Epoch 2, step/total_step: 24440/25001 97.76% Loss:0.2799\n",
      "Epoch 2, step/total_step: 24445/25001 97.78% Loss:0.2132\n",
      "Epoch 2, step/total_step: 24450/25001 97.80% Loss:0.3065\n",
      "Epoch 2, step/total_step: 24455/25001 97.82% Loss:0.2064\n",
      "Epoch 2, step/total_step: 24460/25001 97.84% Loss:0.2060\n",
      "Epoch 2, step/total_step: 24465/25001 97.86% Loss:0.2136\n",
      "Epoch 2, step/total_step: 24470/25001 97.88% Loss:0.1092\n",
      "Epoch 2, step/total_step: 24475/25001 97.90% Loss:0.1874\n",
      "Epoch 2, step/total_step: 24480/25001 97.92% Loss:0.1441\n",
      "Epoch 2, step/total_step: 24485/25001 97.94% Loss:0.1427\n",
      "Epoch 2, step/total_step: 24490/25001 97.96% Loss:0.2146\n",
      "Epoch 2, step/total_step: 24495/25001 97.98% Loss:0.2371\n",
      "Epoch 2, step/total_step: 24500/25001 98.00% Loss:0.2089\n",
      "Epoch 2, step/total_step: 24505/25001 98.02% Loss:0.1777\n",
      "Epoch 2, step/total_step: 24510/25001 98.04% Loss:0.2378\n",
      "Epoch 2, step/total_step: 24515/25001 98.06% Loss:0.1928\n",
      "Epoch 2, step/total_step: 24520/25001 98.08% Loss:0.1917\n",
      "Epoch 2, step/total_step: 24525/25001 98.10% Loss:0.1626\n",
      "Epoch 2, step/total_step: 24530/25001 98.12% Loss:0.2384\n",
      "Epoch 2, step/total_step: 24535/25001 98.14% Loss:0.4794\n",
      "Epoch 2, step/total_step: 24540/25001 98.16% Loss:0.2159\n",
      "Epoch 2, step/total_step: 24545/25001 98.18% Loss:0.2109\n",
      "Epoch 2, step/total_step: 24550/25001 98.20% Loss:0.2381\n",
      "Epoch 2, step/total_step: 24555/25001 98.22% Loss:0.2076\n",
      "Epoch 2, step/total_step: 24560/25001 98.24% Loss:0.1740\n",
      "Epoch 2, step/total_step: 24565/25001 98.26% Loss:0.3442\n",
      "Epoch 2, step/total_step: 24570/25001 98.28% Loss:0.2031\n",
      "Epoch 2, step/total_step: 24575/25001 98.30% Loss:0.2205\n",
      "Epoch 2, step/total_step: 24580/25001 98.32% Loss:0.1879\n",
      "Epoch 2, step/total_step: 24585/25001 98.34% Loss:0.1426\n",
      "Epoch 2, step/total_step: 24590/25001 98.36% Loss:0.2152\n",
      "Epoch 2, step/total_step: 24595/25001 98.38% Loss:0.1811\n",
      "Epoch 2, step/total_step: 24600/25001 98.40% Loss:0.1665\n",
      "Epoch 2, step/total_step: 24605/25001 98.42% Loss:0.1831\n",
      "Epoch 2, step/total_step: 24610/25001 98.44% Loss:0.1825\n",
      "Epoch 2, step/total_step: 24615/25001 98.46% Loss:0.2858\n",
      "Epoch 2, step/total_step: 24620/25001 98.48% Loss:0.1683\n",
      "Epoch 2, step/total_step: 24625/25001 98.50% Loss:0.3038\n",
      "Epoch 2, step/total_step: 24630/25001 98.52% Loss:0.2209\n",
      "Epoch 2, step/total_step: 24635/25001 98.54% Loss:0.1800\n",
      "Epoch 2, step/total_step: 24640/25001 98.56% Loss:0.1652\n",
      "Epoch 2, step/total_step: 24645/25001 98.58% Loss:0.2431\n",
      "Epoch 2, step/total_step: 24650/25001 98.60% Loss:0.1759\n",
      "Epoch 2, step/total_step: 24655/25001 98.62% Loss:0.2065\n",
      "Epoch 2, step/total_step: 24660/25001 98.64% Loss:0.1057\n",
      "Epoch 2, step/total_step: 24665/25001 98.66% Loss:0.1526\n",
      "Epoch 2, step/total_step: 24670/25001 98.68% Loss:0.1854\n",
      "Epoch 2, step/total_step: 24675/25001 98.70% Loss:0.1738\n",
      "Epoch 2, step/total_step: 24680/25001 98.72% Loss:0.1658\n",
      "Epoch 2, step/total_step: 24685/25001 98.74% Loss:0.1437\n",
      "Epoch 2, step/total_step: 24690/25001 98.76% Loss:0.1671\n",
      "Epoch 2, step/total_step: 24695/25001 98.78% Loss:0.2216\n",
      "Epoch 2, step/total_step: 24700/25001 98.80% Loss:0.2795\n",
      "Epoch 2, step/total_step: 24705/25001 98.82% Loss:0.2380\n",
      "Epoch 2, step/total_step: 24710/25001 98.84% Loss:0.2113\n",
      "Epoch 2, step/total_step: 24715/25001 98.86% Loss:0.1636\n",
      "Epoch 2, step/total_step: 24720/25001 98.88% Loss:0.1878\n",
      "Epoch 2, step/total_step: 24725/25001 98.90% Loss:0.1542\n",
      "Epoch 2, step/total_step: 24730/25001 98.92% Loss:0.2211\n",
      "Epoch 2, step/total_step: 24735/25001 98.94% Loss:0.1223\n",
      "Epoch 2, step/total_step: 24740/25001 98.96% Loss:0.1105\n",
      "Epoch 2, step/total_step: 24745/25001 98.98% Loss:0.1496\n",
      "Epoch 2, step/total_step: 24750/25001 99.00% Loss:0.1110\n",
      "Epoch 2, step/total_step: 24755/25001 99.02% Loss:0.2034\n",
      "Epoch 2, step/total_step: 24760/25001 99.04% Loss:0.1204\n",
      "Epoch 2, step/total_step: 24765/25001 99.06% Loss:0.1835\n",
      "Epoch 2, step/total_step: 24770/25001 99.08% Loss:0.1833\n",
      "Epoch 2, step/total_step: 24775/25001 99.10% Loss:0.1366\n",
      "Epoch 2, step/total_step: 24780/25001 99.12% Loss:0.2159\n",
      "Epoch 2, step/total_step: 24785/25001 99.14% Loss:0.1244\n",
      "Epoch 2, step/total_step: 24790/25001 99.16% Loss:0.0847\n",
      "Epoch 2, step/total_step: 24795/25001 99.18% Loss:0.1284\n",
      "Epoch 2, step/total_step: 24800/25001 99.20% Loss:0.0994\n",
      "Epoch 2, step/total_step: 24805/25001 99.22% Loss:0.1205\n",
      "Epoch 2, step/total_step: 24810/25001 99.24% Loss:0.1519\n",
      "Epoch 2, step/total_step: 24815/25001 99.26% Loss:0.1793\n",
      "Epoch 2, step/total_step: 24820/25001 99.28% Loss:0.1145\n",
      "Epoch 2, step/total_step: 24825/25001 99.30% Loss:0.1450\n",
      "Epoch 2, step/total_step: 24830/25001 99.32% Loss:0.1034\n",
      "Epoch 2, step/total_step: 24835/25001 99.34% Loss:0.0930\n",
      "Epoch 2, step/total_step: 24840/25001 99.36% Loss:0.1073\n",
      "Epoch 2, step/total_step: 24845/25001 99.38% Loss:0.2289\n",
      "Epoch 2, step/total_step: 24850/25001 99.40% Loss:0.0957\n",
      "Epoch 2, step/total_step: 24855/25001 99.42% Loss:0.1038\n",
      "Epoch 2, step/total_step: 24860/25001 99.44% Loss:0.1498\n",
      "Epoch 2, step/total_step: 24865/25001 99.46% Loss:0.1512\n",
      "Epoch 2, step/total_step: 24870/25001 99.48% Loss:0.0921\n",
      "Epoch 2, step/total_step: 24875/25001 99.50% Loss:0.1239\n",
      "Epoch 2, step/total_step: 24880/25001 99.52% Loss:0.1687\n",
      "Epoch 2, step/total_step: 24885/25001 99.54% Loss:0.1406\n",
      "Epoch 2, step/total_step: 24890/25001 99.56% Loss:0.1665\n",
      "Epoch 2, step/total_step: 24895/25001 99.58% Loss:0.1182\n",
      "Epoch 2, step/total_step: 24900/25001 99.60% Loss:0.0614\n",
      "Epoch 2, step/total_step: 24905/25001 99.62% Loss:0.0640\n",
      "Epoch 2, step/total_step: 24910/25001 99.64% Loss:0.1176\n",
      "Epoch 2, step/total_step: 24915/25001 99.66% Loss:0.2048\n",
      "Epoch 2, step/total_step: 24920/25001 99.68% Loss:0.0803\n",
      "Epoch 2, step/total_step: 24925/25001 99.70% Loss:0.1751\n",
      "Epoch 2, step/total_step: 24930/25001 99.72% Loss:0.1012\n",
      "Epoch 2, step/total_step: 24935/25001 99.74% Loss:0.0403\n",
      "Epoch 2, step/total_step: 24940/25001 99.76% Loss:0.0583\n",
      "Epoch 2, step/total_step: 24945/25001 99.78% Loss:0.0481\n",
      "Epoch 2, step/total_step: 24950/25001 99.80% Loss:0.0893\n",
      "Epoch 2, step/total_step: 24955/25001 99.82% Loss:0.1034\n",
      "Epoch 2, step/total_step: 24960/25001 99.84% Loss:0.3311\n",
      "Epoch 2, step/total_step: 24965/25001 99.86% Loss:0.1755\n",
      "Epoch 2, step/total_step: 24970/25001 99.88% Loss:0.2003\n",
      "Epoch 2, step/total_step: 24975/25001 99.90% Loss:0.1378\n",
      "Epoch 2, step/total_step: 24980/25001 99.92% Loss:0.1936\n",
      "Epoch 2, step/total_step: 24985/25001 99.94% Loss:0.2300\n",
      "Epoch 2, step/total_step: 24990/25001 99.96% Loss:0.1818\n",
      "Epoch 2, step/total_step: 24995/25001 99.98% Loss:0.0904\n",
      "Epoch 2, step/total_step: 25000/25001 100.00% Loss:0.1433\n",
      "保存模型...\n",
      "Epoch 2, Val Loss:3.9738\n",
      "训练完毕,共用时9229秒.\n"
     ]
    }
   ],
   "source": [
    "lstmcrf_pred = bilstm_train_and_eval(\n",
    "    (train_word_lists, train_tag_lists),\n",
    "    (dev_word_lists, dev_tag_lists),\n",
    "    (test_word_lists, test_tag_lists),\n",
    "    crf_word2id, crf_tag2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tag_lists,test_tag_lists = lstmcrf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(44823, 44823)"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "len(pred_tag_lists),len(test_tag_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(47, 48)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "len(pred_tag_lists[0]),len(test_tag_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_tag_lists)):\n",
    "    del(test_tag_lists[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "len(pred_tag_lists[2]),len(test_tag_lists[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_tag_lists[1],test_tag_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_lists(lists):\n",
    "    flatten_list = []\n",
    "    for l in lists:\n",
    "        if type(l) == list:\n",
    "            flatten_list += l\n",
    "        else:\n",
    "            flatten_list.append(l)\n",
    "    return flatten_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = flatten_lists(pred_tag_lists)\n",
    "true_list = flatten_lists(test_tag_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           precision    recall  f1-score   support\n",
      "    I-HOS     0.9945    0.9546    0.9741    178553\n",
      "    E-ORG     0.7874    0.9752    0.8713    106388\n",
      "    B-LOC     0.9533    0.9999    0.9760     23647\n",
      "    B-HOS     0.9854    0.9548    0.9698     23229\n",
      "    B-ORG     0.7840    0.9711    0.8676    106388\n",
      "    I-LOC     0.9906    0.9992    0.9949      3922\n",
      "    I-ORG     0.9300    0.9829    0.9557    118658\n",
      "    E-HOS     0.9951    0.9693    0.9821     23229\n",
      "    E-LOC     0.9535    0.9997    0.9760     23647\n",
      "        O     0.9945    0.9677    0.9809   1908018\n",
      "avg/total     0.9729    0.9685    0.9696   2515679\n",
      "\n",
      "Confusion Matrix:\n",
      "          I-HOS   E-ORG   B-LOC   B-HOS   B-ORG   I-LOC   I-ORG   E-HOS   E-LOC       O \n",
      "  I-HOS  170449     392       1     201     806      18      51       0     141    6494 \n",
      "  E-ORG      90  103753       0       0      12       0    1736      11       6     780 \n",
      "  B-LOC       0       1   23644       0       0       1       0       0       0       1 \n",
      "  B-HOS      19       3     146   22178      11       0       2       0       0     870 \n",
      "  B-ORG     100       5      11       1  103318       0    2133       0       0     820 \n",
      "  I-LOC       0       0       1       0       0    3919       0       0       1       1 \n",
      "  I-ORG       3     473       5       0     511       1  116633       0      10    1022 \n",
      "  E-HOS       1     405       0       0       0       0       0   22516       0     307 \n",
      "  E-LOC       1       0       1       0       0       4       0       0   23639       2 \n",
      "      O     731   26728     994     127   27122      13    4860      99     995 1846349 \n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics(true_list, predict_list, remove_O=False)\n",
    "metrics.report_scores()\n",
    "metrics.report_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity(sent,word2id,model,tag2id):\n",
    "    sent_list = []\n",
    "    for i in range(len(sent)):\n",
    "        sent_list.append(sent[i])\n",
    "    sent_list.append('<end>')\n",
    "\n",
    "    pred_tag_lists, test_tag_lists = model.test(\n",
    "        [sent_list], [[]], word2id, tag2id)\n",
    "  \n",
    "    pred_tag_lists = pred_tag_lists[0]\n",
    "\n",
    "    entity_idxs = []\n",
    "    location_idxs = []\n",
    "    hospital_idxs = []\n",
    "    for i in range(len(pred_tag_lists)):\n",
    "        entity_idx1 = []\n",
    "        if pred_tag_lists[i]=='B-ORG':\n",
    "            entity_idx1.append(i)\n",
    "            for j in range(i+1,len(pred_tag_lists)):\n",
    "                if pred_tag_lists[j]=='E-ORG':\n",
    "                    entity_idx1.append(j)\n",
    "                    break\n",
    "        entity_idx2 = []\n",
    "        if pred_tag_lists[i]=='B-LOC':\n",
    "            entity_idx2.append(i)\n",
    "            for j in range(i+1,len(pred_tag_lists)):\n",
    "                if pred_tag_lists[j]=='E-LOC':\n",
    "                    entity_idx2.append(j)\n",
    "                    break\n",
    "        entity_idx3 = []\n",
    "        if pred_tag_lists[i]=='B-HOS':\n",
    "            entity_idx3.append(i)\n",
    "            for j in range(i+1,len(pred_tag_lists)):\n",
    "                if pred_tag_lists[j]=='E-HOS':\n",
    "                    entity_idx3.append(j)\n",
    "                    break\n",
    "            \n",
    "        if entity_idx1!=[]:\n",
    "            entity_idxs.append(entity_idx1)\n",
    "        if entity_idx2!=[]:\n",
    "            location_idxs.append(entity_idx2)\n",
    "        if entity_idx3!=[]:\n",
    "            hospital_idxs.append(entity_idx3)\n",
    "    \n",
    "    entity_list = []\n",
    "    for pos in entity_idxs:\n",
    "        words = sent[pos[0]:(pos[1]+1)]\n",
    "        entity_list.append(words)\n",
    "    \n",
    "    location_list = []\n",
    "    for pos in location_idxs:\n",
    "        words = sent[pos[0]:(pos[1]+1)]\n",
    "        location_list.append(words)\n",
    "\n",
    "    hospital_list = []\n",
    "    for pos in hospital_idxs:\n",
    "        words = sent[pos[0]:(pos[1]+1)]\n",
    "        hospital_list.append(words)\n",
    "    data_dict = {'项目':list(set(entity_list)),'地区':list(set(location_list)),'机构':list(set(hospital_list))}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(crf_word2id,open('data/new_word2id.txt','w'))\n",
    "json.dump(crf_tag2id,open('data/new_tag2id.txt','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/pro_city_hosbilstm_crf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_word2id = json.load(open('data/pro_city_hos_word2id.txt'))\n",
    "crf_tag2id = json.load(open('data/pro_city_hos_tag2id.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-ORG': 1,\n",
       " 'I-ORG': 2,\n",
       " 'E-ORG': 3,\n",
       " 'B-LOC': 4,\n",
       " 'E-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " '<pad>': 7,\n",
       " '<start>': 8,\n",
       " '<end>': 9}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "crf_tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ff10da58b43c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'我的鼻子非常扁平，而且鼻子也非常不好看，听说我这种情况去做综合隆鼻的手术是比较好的，想问一下北京的综合隆鼻价格是多少？请问扬州广陵艾菲斯医疗美容门诊部的价格怎么样?'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextract_entity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrf_word2id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrf_tag2id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-d8a7ebca174f>\u001b[0m in \u001b[0;36mextract_entity\u001b[1;34m(sent, word2id, model, tag2id)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mentity_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentity_idxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mentity_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent = '我的鼻子非常扁平，而且鼻子也非常不好看，听说我这种情况去做综合隆鼻的手术是比较好的，想问一下北京的综合隆鼻价格是多少？请问扬州广陵艾菲斯医疗美容门诊部的价格怎么样?'\n",
    "extract_entity(sent,crf_word2id,model,crf_tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'项目': [], '地区': ['武汉'], '机构': []}"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "sent = '武汉轻工大学怎么样?'\n",
    "extract_entity(sent,crf_word2id,model,crf_tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}